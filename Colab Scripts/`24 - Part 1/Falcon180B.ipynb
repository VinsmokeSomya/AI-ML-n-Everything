{"cells":[{"cell_type":"code","execution_count":null,"id":"a004c675","metadata":{"scrolled":true,"id":"a004c675"},"outputs":[],"source":["# Install stuff\n","!pip install transformers==4.33.0 accelerate optimum scipy auto-gptq -U"]},{"cell_type":"code","execution_count":null,"id":"0e236504","metadata":{"id":"0e236504"},"outputs":[],"source":["# Import dependencies\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer"]},{"cell_type":"code","execution_count":null,"id":"51c5623f","metadata":{"id":"51c5623f"},"outputs":[],"source":["# Specify model name\n","model_name = \"TheBloke/Falcon-180B-Chat-GPTQ\""]},{"cell_type":"code","execution_count":null,"id":"095dc972","metadata":{"id":"095dc972"},"outputs":[],"source":["# Load quantized model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    revision=\"main\", cache_dir='workspace/models/')"]},{"cell_type":"code","execution_count":null,"id":"d491b918","metadata":{"scrolled":true,"id":"d491b918"},"outputs":[],"source":["# Make it better\n","model.to_bettertransformer()"]},{"cell_type":"code","execution_count":null,"id":"d6fae9bb","metadata":{"id":"d6fae9bb"},"outputs":[],"source":["# Load up tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)"]},{"cell_type":"code","execution_count":null,"id":"42e9ff8f","metadata":{"id":"42e9ff8f"},"outputs":[],"source":["# Setup a prompt\n","prompt = \"\"\"Explain in a short paragraph quantum field theory to a high-school student.\"\"\"\n","\n","# Pass the prompt to the tokenizer\n","inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","# Setup the text streamer\n","streamer = TextStreamer(tokenizer, skip_prompt=True)"]},{"cell_type":"code","execution_count":null,"id":"22633ba6","metadata":{"jupyter":{"source_hidden":true},"id":"22633ba6"},"outputs":[],"source":["del inputs['token_type_ids']"]},{"cell_type":"code","execution_count":null,"id":"db96df7b","metadata":{"id":"db96df7b"},"outputs":[],"source":["# Actually run the thing\n","output = model.generate(**inputs,\n","                        streamer=streamer,\n","                        use_cache=True,\n","                        max_new_tokens=60)"]},{"cell_type":"code","execution_count":null,"id":"7824d6eb","metadata":{"id":"7824d6eb"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[{"file_id":"https://github.com/nicknochnack/Falcon180b/blob/main/Falcon180B.ipynb","timestamp":1709874687679}]}},"nbformat":4,"nbformat_minor":5}